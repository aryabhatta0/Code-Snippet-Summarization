{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-07T06:36:04.478684Z","iopub.execute_input":"2023-07-07T06:36:04.479130Z","iopub.status.idle":"2023-07-07T06:36:04.495802Z","shell.execute_reply.started":"2023-07-07T06:36:04.479096Z","shell.execute_reply":"2023-07-07T06:36:04.494584Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"/kaggle/input/1epoch-model-sourcecodemodel/x_tokenizer.pickle\n/kaggle/input/1epoch-model-sourcecodemodel/trained_model.h5\n/kaggle/input/1epoch-model-sourcecodemodel/y_tokenizer.pickle\n/kaggle/input/1epoch-model-sourcecodemodel/decoder_model.h5\n/kaggle/input/1epoch-model-sourcecodemodel/encoder_model.h5\n/kaggle/input/python-dataset-source-code-summarization/preprocess.py\n/kaggle/input/python-dataset-source-code-summarization/python_test_dataset.csv\n/kaggle/input/python-dataset-source-code-summarization/python_Sample_dataset.csv\n/kaggle/input/python-dataset-source-code-summarization/python_dataset/python_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pickle\n# from preprocess import preprocess, tokenize","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.499117Z","iopub.execute_input":"2023-07-07T06:36:04.499680Z","iopub.status.idle":"2023-07-07T06:36:04.507010Z","shell.execute_reply.started":"2023-07-07T06:36:04.499636Z","shell.execute_reply":"2023-07-07T06:36:04.505620Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/python-dataset-source-code-summarization')\n\nfrom preprocess import preprocess, tokenize","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.515346Z","iopub.execute_input":"2023-07-07T06:36:04.515856Z","iopub.status.idle":"2023-07-07T06:36:04.530262Z","shell.execute_reply.started":"2023-07-07T06:36:04.515803Z","shell.execute_reply":"2023-07-07T06:36:04.528784Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"**Loading trained files:**","metadata":{}},{"cell_type":"code","source":"# tokenizers\nx_tokenizer_path = \"/kaggle/input/1epoch-model-sourcecodemodel/x_tokenizer.pickle\"\ny_tokenizer_path = \"/kaggle/input/1epoch-model-sourcecodemodel/y_tokenizer.pickle\"\nwith open(x_tokenizer_path, 'rb') as handle:\n    x_tokenizer = pickle.load(handle)\nwith open(y_tokenizer_path, 'rb') as handle:\n    y_tokenizer = pickle.load(handle)\n\n# models\n# from tensorflow.keras.models import load_model\n\n# model = load_model('/kaggle/input/1epoch-model-sourcecodemodel/trained_model.h5')\n# encoder_model = load_model('/kaggle/input/1epoch-model-sourcecodemodel/encoder_model.h5')\n# decoder_model = load_model('/kaggle/input/1epoch-model-sourcecodemodel/decoder_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.532684Z","iopub.execute_input":"2023-07-07T06:36:04.533151Z","iopub.status.idle":"2023-07-07T06:36:04.639039Z","shell.execute_reply.started":"2023-07-07T06:36:04.533108Z","shell.execute_reply":"2023-07-07T06:36:04.637736Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# confirm loadings\nx_vocab_size = x_tokenizer.num_words + 1\nprint(\"X Vocab Size: \", x_vocab_size)\ny_vocab_size = y_tokenizer.num_words + 1\nprint(\"Y Vocab Size: \", y_vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.643026Z","iopub.execute_input":"2023-07-07T06:36:04.643471Z","iopub.status.idle":"2023-07-07T06:36:04.650080Z","shell.execute_reply.started":"2023-07-07T06:36:04.643427Z","shell.execute_reply":"2023-07-07T06:36:04.648981Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"X Vocab Size:  26090\nY Vocab Size:  10603\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.651590Z","iopub.execute_input":"2023-07-07T06:36:04.652331Z","iopub.status.idle":"2023-07-07T06:36:04.707941Z","shell.execute_reply.started":"2023-07-07T06:36:04.652300Z","shell.execute_reply":"2023-07-07T06:36:04.706645Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 100, 200)     5218000     ['input_1[0][0]']                \n                                                                                                  \n lstm (LSTM)                    [(None, 100, 300),   601200      ['embedding[0][0]']              \n                                 (None, 300),                                                     \n                                 (None, 300)]                                                     \n                                                                                                  \n input_2 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n lstm_1 (LSTM)                  [(None, 100, 300),   721200      ['lstm[0][0]']                   \n                                 (None, 300),                                                     \n                                 (None, 300)]                                                     \n                                                                                                  \n embedding_1 (Embedding)        (None, None, 200)    2120600     ['input_2[0][0]']                \n                                                                                                  \n lstm_2 (LSTM)                  [(None, 100, 300),   721200      ['lstm_1[0][0]']                 \n                                 (None, 300),                                                     \n                                 (None, 300)]                                                     \n                                                                                                  \n lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n                                 (None, 300),                     'lstm_2[0][1]',                 \n                                 (None, 300)]                     'lstm_2[0][2]']                 \n                                                                                                  \n time_distributed (TimeDistribu  (None, None, 10603)  3191503    ['lstm_3[0][0]']                 \n ted)                                                                                             \n                                                                                                  \n==================================================================================================\nTotal params: 13,174,903\nTrainable params: 13,174,903\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Utilities for Prediction:**","metadata":{}},{"cell_type":"code","source":"max_code_len = 100\nmax_summary_len = 25","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.710780Z","iopub.execute_input":"2023-07-07T06:36:04.711152Z","iopub.status.idle":"2023-07-07T06:36:04.716251Z","shell.execute_reply.started":"2023-07-07T06:36:04.711119Z","shell.execute_reply":"2023-07-07T06:36:04.715022Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"reverse_target_word_index = y_tokenizer.index_word\nreverse_source_word_index = x_tokenizer.index_word\ntarget_word_index = y_tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.717637Z","iopub.execute_input":"2023-07-07T06:36:04.718460Z","iopub.status.idle":"2023-07-07T06:36:04.733242Z","shell.execute_reply.started":"2023-07-07T06:36:04.718423Z","shell.execute_reply":"2023-07-07T06:36:04.731944Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# reverse_target_word_index","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.735040Z","iopub.execute_input":"2023-07-07T06:36:04.735377Z","iopub.status.idle":"2023-07-07T06:36:04.745848Z","shell.execute_reply.started":"2023-07-07T06:36:04.735348Z","shell.execute_reply":"2023-07-07T06:36:04.744556Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# for generating the predicted decoded sequence\ndef predict_summary(input_seq):\n\n    # Encode the input as state vectors.\n    (e_out, e_h, e_c) = encoder_model.predict(input_seq, verbose=0)\n\n    # Generate empty target sequence of length 1\n    target_seq = np.zeros((1, 1))\n\n    # Populate the first word of target sequence with the start word.\n    target_seq[0, 0] = target_word_index['sostok']\n\n    stop_condition = False\n    decoded_sentence = ''\n\n    while not stop_condition:\n        (output_tokens, h, c) = decoder_model.predict([target_seq]\n                + [e_out, e_h, e_c], verbose=0)\n\n        # Sample a token with the highest probability\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        # TODO: Pick 2nd max prob, if sampled_token_index=0\n        if(sampled_token_index == 0):\n            sampled_token_index = np.argsort(output_tokens[0, -1, :])[-2]\n\n        sampled_token = reverse_target_word_index[sampled_token_index]\n\n        if sampled_token != 'eostok':\n            decoded_sentence += ' ' + sampled_token\n\n        # Exit condition: either hit max length or find the stop word.\n        if sampled_token == 'eostok' or len(decoded_sentence.split()) >= max_summary_len - 1:\n            stop_condition = True\n\n        # Update the target sequence (of length 1)\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update internal states\n        (e_h, e_c) = (h, c)      # Check\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.747294Z","iopub.execute_input":"2023-07-07T06:36:04.747769Z","iopub.status.idle":"2023-07-07T06:36:04.765279Z","shell.execute_reply.started":"2023-07-07T06:36:04.747737Z","shell.execute_reply":"2023-07-07T06:36:04.763899Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# # same as predict_summary\n# def predict_summary2(input_seq):\n#     enc_out, enc_h, enc_c = encoder_model.predict(input_seq, verbose=0)\n#     target_seq = np.zeros((1, 1))\n#     target_seq[0, 0] = target_word_index['sostok']\n#     stop_condition = False\n#     decoded_sentence = ''\n    \n#     while not stop_condition:\n#         output_token, h, c = decoder_model.predict([target_seq] + [enc_out, enc_h, enc_c], verbose=0)\n#         sampled_token_index = np.argmax(output_token[0, -1, :])\n#         sampled_token = reverse_target_word_index[sampled_token_index]\n#         if sampled_token != 'eostok':\n#             decoded_sentence += ' ' + sampled_token\n#         if sampled_token == 'eostok' or len(decoded_sentence.split()) >= max_summary_len - 1:\n#             stop_condition = True\n#         target_seq = np.zeros((1, 1))\n#         target_seq[0, 0] = sampled_token_index\n#         enc_out, enc_h, enc_c = h, c, enc_out\n#     return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.767230Z","iopub.execute_input":"2023-07-07T06:36:04.767747Z","iopub.status.idle":"2023-07-07T06:36:04.783049Z","shell.execute_reply.started":"2023-07-07T06:36:04.767695Z","shell.execute_reply":"2023-07-07T06:36:04.781822Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Utility functions to generate strings sequences from integer (token) sequences\ndef seq2summary(input_seq):\n    newString = ''\n    for i in input_seq:\n        if i != 0 and i != target_word_index['sostok'] and i != target_word_index['eostok']:\n            newString += reverse_target_word_index[i] + ' '\n\n    return newString\n\ndef seq2code(input_seq):\n    newString = ''\n    for i in input_seq:\n        if i != 0:\n            newString += reverse_source_word_index[i] + ' '\n\n    return newString","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.784758Z","iopub.execute_input":"2023-07-07T06:36:04.785291Z","iopub.status.idle":"2023-07-07T06:36:04.802188Z","shell.execute_reply.started":"2023-07-07T06:36:04.785244Z","shell.execute_reply":"2023-07-07T06:36:04.800847Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"**Test Dataset and Prediction:**","metadata":{}},{"cell_type":"code","source":"testpath = \"/kaggle/input/python-dataset-source-code-summarization/python_test_dataset.csv\"\ntest = pd.read_csv(testpath)\ntest = test[['code', 'docstring']]\nprint(test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.805434Z","iopub.execute_input":"2023-07-07T06:36:04.806200Z","iopub.status.idle":"2023-07-07T06:36:04.827217Z","shell.execute_reply.started":"2023-07-07T06:36:04.806167Z","shell.execute_reply":"2023-07-07T06:36:04.826155Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"(99, 2)\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"                                                code  \\\n0    sum(d * 10 ** i for i, d in enumerate(x[::-1]))   \n1                      r = int(''.join(map(str, x)))   \n2  datetime.strptime('2010-11-13 10:33:54.227806'...   \n3  [(i, sum(j) / len(j)) for i, j in list(d.items...   \n4                                zip([1, 2], [3, 4])   \n\n                                           docstring  \n0  How to convert a list of multiple integers int...  \n1  How to convert a list of multiple integers int...  \n2  how to convert a datetime string back to datet...  \n3  Averaging the values in a dictionary based on ...  \n4                                zip lists in python  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>docstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sum(d * 10 ** i for i, d in enumerate(x[::-1]))</td>\n      <td>How to convert a list of multiple integers int...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>r = int(''.join(map(str, x)))</td>\n      <td>How to convert a list of multiple integers int...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>datetime.strptime('2010-11-13 10:33:54.227806'...</td>\n      <td>how to convert a datetime string back to datet...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[(i, sum(j) / len(j)) for i, j in list(d.items...</td>\n      <td>Averaging the values in a dictionary based on ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zip([1, 2], [3, 4])</td>\n      <td>zip lists in python</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# preprocess test\npost_test = preprocess(test, max_code_len, max_summary_len)\nprint(post_test.shape)\npost_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.828467Z","iopub.execute_input":"2023-07-07T06:36:04.829247Z","iopub.status.idle":"2023-07-07T06:36:04.862201Z","shell.execute_reply.started":"2023-07-07T06:36:04.829214Z","shell.execute_reply":"2023-07-07T06:36:04.861087Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"(99, 2)\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"                            code  \\\n0   sum i for d in enumerate ::    \n1            r int join map str    \n2       datetime strptime m h s    \n3   sum len for j in list items    \n4                           zip    \n\n                                           docstring  \n0  sostok how to convert list of multiple integer...  \n1  sostok how to convert list of multiple integer...  \n2  sostok how to convert datetime string back to ...  \n3  sostok averaging the values in dictionary base...  \n4                  sostok zip lists in python eostok  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>docstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sum i for d in enumerate ::</td>\n      <td>sostok how to convert list of multiple integer...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>r int join map str</td>\n      <td>sostok how to convert list of multiple integer...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>datetime strptime m h s</td>\n      <td>sostok how to convert datetime string back to ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sum len for j in list items</td>\n      <td>sostok averaging the values in dictionary base...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zip</td>\n      <td>sostok zip lists in python eostok</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# tokenize test\ntest_code = tokenize(list(post_test['code'].values), max_pad_len=max_code_len, tokenizer_path=x_tokenizer_path, thresh=3, fit_on_texts=False)\ntest_summary = tokenize(list(post_test['docstring'].values), max_pad_len=max_summary_len, tokenizer_path=y_tokenizer_path, thresh=2, fit_on_texts=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.863518Z","iopub.execute_input":"2023-07-07T06:36:04.863824Z","iopub.status.idle":"2023-07-07T06:36:04.944432Z","shell.execute_reply.started":"2023-07-07T06:36:04.863798Z","shell.execute_reply":"2023-07-07T06:36:04.942939Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"test_code","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.946066Z","iopub.execute_input":"2023-07-07T06:36:04.946548Z","iopub.status.idle":"2023-07-07T06:36:04.955696Z","shell.execute_reply.started":"2023-07-07T06:36:04.946517Z","shell.execute_reply":"2023-07-07T06:36:04.954145Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([[111, 118,   2, ...,   0,   0,   0],\n       [160,  64,  66, ...,   0,   0,   0],\n       [105, 560, 140, ...,   0,   0,   0],\n       ...,\n       [ 29,   2,  20, ...,   0,   0,   0],\n       [ 53,  27,  48, ...,   0,   0,   0],\n       [ 58, 388,  59, ...,   0,   0,   0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"# predict for some of the sequences\nfor i in range(0, 5):\n    print ('Code:', seq2code(test_code[i]))\n    print ('Original summary:', seq2summary(test_summary[i]))\n    print ('Predicted summary:', predict_summary(test_code[i].reshape(1, max_code_len)))\n#     print ('Predicted summary:', predict_summary2(test_code[i].reshape(1, max_code_len, 1)))\n    print ('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:04.957646Z","iopub.execute_input":"2023-07-07T06:36:04.958728Z","iopub.status.idle":"2023-07-07T06:36:12.284853Z","shell.execute_reply.started":"2023-07-07T06:36:04.958674Z","shell.execute_reply":"2023-07-07T06:36:12.283655Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Code: sum i for d in enumerate \nOriginal summary: how to convert list of multiple integers into single integer \nPredicted summary:  how to get the number of the elements of list of list of lists\n\n\nCode: r int join map str \nOriginal summary: how to convert list of multiple integers into single integer \nPredicted summary:  how to get the number of the elements of list of list of lists\n\n\nCode: datetime strptime m h s \nOriginal summary: how to convert datetime string back to datetime object \nPredicted summary:  how to get the number of the elements of list of list of lists\n\n\nCode: sum len for j in list items \nOriginal summary: averaging the values in dictionary based on the key \nPredicted summary:  how to get the number of the elements of list of list of lists\n\n\nCode: zip \nOriginal summary: zip lists in python \nPredicted summary:  how to get the number of the elements of list of list of lists\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# prediction for any new input\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ndef predict(input_string):\n    input_seq = x_tokenizer.texts_to_sequences([input_string])\n    input_seq = pad_sequences(input_seq, maxlen=max_code_len, padding='post')\n#     pred_sent = decode_sequence(input_seq.reshape(1, max_code_len, 1))\n    pred_sent = predict_summary(test_code[i].reshape(1, max_code_len))\n    return pred_sent","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:12.286461Z","iopub.execute_input":"2023-07-07T06:36:12.286894Z","iopub.status.idle":"2023-07-07T06:36:12.294683Z","shell.execute_reply.started":"2023-07-07T06:36:12.286854Z","shell.execute_reply":"2023-07-07T06:36:12.293253Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"predict(\"print last modified time ctime os path getmtime file\")","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:12.296075Z","iopub.execute_input":"2023-07-07T06:36:12.296389Z","iopub.status.idle":"2023-07-07T06:36:13.795729Z","shell.execute_reply.started":"2023-07-07T06:36:12.296362Z","shell.execute_reply":"2023-07-07T06:36:13.794340Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"' how to get the number of the elements of list of list of lists'"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:36:56.987566Z","iopub.execute_input":"2023-07-07T06:36:56.987955Z","iopub.status.idle":"2023-07-07T06:36:57.712375Z","shell.execute_reply.started":"2023-07-07T06:36:56.987924Z","shell.execute_reply":"2023-07-07T06:36:57.710983Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# BLEU Score for test\nbleu_score = 0\ndiff = 0\n\nfor i in range(len(test_code)):\n\n    pred_summary = predict_summary(test_code[i].reshape(1, max_code_len))\n    # print(pred_summary)\n    # print(seq2summary(y_val[i]))\n\n    # BLEU score\n    curr_bleu = sentence_bleu(pred_summary, seq2summary(test_summary[i]).split())\n#     curr_bleu = sacrebleu.sentence_bleu(pred_summary, (post_test['docstring'][i]).split(), smooth_method='exp').score\n#     curr_bleu = sentence_bleu(pred_summary.split(), post_test['docstring'][i].split())\n    print(curr_bleu)\n    bleu_score += curr_bleu\n\n    # Check if below threshold\n    if curr_bleu < 5:\n        diff += 1\n\n# average_test_bleu_score = bleu_score / (len(test_code) - diff)\naverage_test_bleu_score = bleu_score / (len(test_code))\nprint(\"Average BLEU Score on val:\", average_test_bleu_score)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:39:25.401474Z","iopub.execute_input":"2023-07-07T06:39:25.401897Z","iopub.status.idle":"2023-07-07T06:39:48.400132Z","shell.execute_reply.started":"2023-07-07T06:39:25.401863Z","shell.execute_reply":"2023-07-07T06:39:48.398615Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_code)):\n\u001b[0;32m----> 7\u001b[0m     pred_summary \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_code\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_code_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(pred_summary)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(seq2summary(y_val[i]))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# BLEU score\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     curr_bleu \u001b[38;5;241m=\u001b[39m sentence_bleu(pred_summary, seq2summary(test_summary[i])\u001b[38;5;241m.\u001b[39msplit())\n","Cell \u001b[0;32mIn[61], line 17\u001b[0m, in \u001b[0;36mpredict_summary\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     14\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[0;32m---> 17\u001b[0m     (output_tokens, h, c) \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43me_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_c\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Sample a token with the highest probability\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2378\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2376\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[1;32m   2377\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2380\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py:1305\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1305\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:505\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    504\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:713\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    709\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    711\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 713\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:752\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    750\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    751\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 752\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3407\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3408\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3409\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3411\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}